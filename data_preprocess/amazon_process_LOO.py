{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. 先处理meta_{data}.json.gz文件，读取并清洗后，得到df_meta 也就是item table",
   "id": "1b516ff56e8078fc"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:11.200194Z",
     "start_time": "2025-12-09T04:19:12.029427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "class Args:\n",
    "    raw_data_dir = '../raw_data'\n",
    "    processed_data_dir = '../dataset'\n",
    "    dataset = 'Toys_and_Games'\n",
    "# ['Sports_and_Outdoors', 'Beauty', 'Toys_and_Games', 'Yelp']\n",
    "\n",
    "args = Args()\n",
    "\n",
    "print(f'Start preprocessing {args.dataset} at {start_time}...')\n",
    "# 第一步先处理meta_{data}.json.gz\n",
    "#   \"asin\": \"0000031852\",\n",
    "#   \"title\": \"Girls Ballet Tutu Zebra Hot Pink\",\n",
    "#   \"price\": 3.17,\n",
    "#   \"imUrl\": \"http://ecx.images-amazon.com/images/I/51fAmVkTbyL._SY300_.jpg\",\n",
    "#   \"related\":\n",
    "#   {\n",
    "#     \"also_bought\": [\"B00D103F8U\", \"B007R2RM8W\"],\n",
    "#     \"also_viewed\": [\"B00E79VW6Q\", \"B00D10CLVW\", \"B00B0AVO54\", \"B00E95LC8Q\", \"B00GOR92SO\", \"B007ZN5Y56\", \"B00AL2569W\", \"B00B608000\", \"B008F0SMUC\", \"B00BFXLZ8M\"],\n",
    "#     \"bought_together\": [\"B002BZX8Z6\"]\n",
    "#   },\n",
    "#   \"salesRank\": {\"Toys & Games\": 211836},\n",
    "#   \"brand\": \"Coxlures\",\n",
    "#   \"categories\": [[\"Sports & Outdoors\", \"Other Sports\", \"Dance\"]]\n",
    "\n",
    "filename = f\"{args.raw_data_dir}/{args.dataset}/meta_{args.dataset}.json.gz\"\n",
    "\n",
    "def parse(path):\n",
    "    with gzip.open(path, 'rb') as g:\n",
    "        for l in g:\n",
    "            yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF(filename)\n"
   ],
   "id": "aa772f2a41f46be1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preprocessing Toys_and_Games at 2025-12-09-12-19-12...\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:11.253274Z",
     "start_time": "2025-12-09T04:20:11.237138Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "a42b58d282611cfd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         asin                                        description  \\\n",
       "0  0000191639  Three Dr. Suess' Puzzles: Green Eggs and Ham, ...   \n",
       "1  0005069491                                                NaN   \n",
       "2  0076561046  Learn Fractions Decimals Percents using flash ...   \n",
       "3  0131358936  New, Sealed. Fast Shipping with tracking, buy ...   \n",
       "4  0133642984                                                NaN   \n",
       "\n",
       "                                            title   price  \\\n",
       "0  Dr. Suess 19163 Dr. Seuss Puzzle 3 Pack Bundle   37.12   \n",
       "1                        Nursery Rhymes Felt Book     NaN   \n",
       "2              Fraction Decimal Percent Card Deck     NaN   \n",
       "3                                             NaN   36.22   \n",
       "4             Algebra 2 California Teacher Center  731.93   \n",
       "\n",
       "                   salesRank  \\\n",
       "0   {'Toys & Games': 612379}   \n",
       "1   {'Toys & Games': 576683}   \n",
       "2   {'Toys & Games': 564211}   \n",
       "3         {'Software': 8080}   \n",
       "4  {'Toys & Games': 1150291}   \n",
       "\n",
       "                                               imUrl          brand  \\\n",
       "0  http://ecx.images-amazon.com/images/I/414PLROX...      Dr. Seuss   \n",
       "1  http://ecx.images-amazon.com/images/I/51z4JDBC...            NaN   \n",
       "2  http://ecx.images-amazon.com/images/I/51ObabPu...            NaN   \n",
       "3  http://ecx.images-amazon.com/images/I/51%2B7Ej...            NaN   \n",
       "4  http://ecx.images-amazon.com/images/I/51VK%2BL...  Prentice Hall   \n",
       "\n",
       "                                          categories  \\\n",
       "0          [[Toys & Games, Puzzles, Jigsaw Puzzles]]   \n",
       "1                                   [[Toys & Games]]   \n",
       "2  [[Toys & Games, Learning & Education, Flash Ca...   \n",
       "3  [[Toys & Games, Learning & Education, Mathemat...   \n",
       "4  [[Toys & Games, Learning & Education, Mathemat...   \n",
       "\n",
       "                                             related  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                    {'also_viewed': ['0075728680']}  \n",
       "3  {'also_bought': ['0321845536', '0078787572'], ...  \n",
       "4                                                NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>imUrl</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000191639</td>\n",
       "      <td>Three Dr. Suess' Puzzles: Green Eggs and Ham, ...</td>\n",
       "      <td>Dr. Suess 19163 Dr. Seuss Puzzle 3 Pack Bundle</td>\n",
       "      <td>37.12</td>\n",
       "      <td>{'Toys &amp; Games': 612379}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/414PLROX...</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>[[Toys &amp; Games, Puzzles, Jigsaw Puzzles]]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005069491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nursery Rhymes Felt Book</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Toys &amp; Games': 576683}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51z4JDBC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Toys &amp; Games]]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0076561046</td>\n",
       "      <td>Learn Fractions Decimals Percents using flash ...</td>\n",
       "      <td>Fraction Decimal Percent Card Deck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Toys &amp; Games': 564211}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51ObabPu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Toys &amp; Games, Learning &amp; Education, Flash Ca...</td>\n",
       "      <td>{'also_viewed': ['0075728680']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0131358936</td>\n",
       "      <td>New, Sealed. Fast Shipping with tracking, buy ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.22</td>\n",
       "      <td>{'Software': 8080}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51%2B7Ej...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Toys &amp; Games, Learning &amp; Education, Mathemat...</td>\n",
       "      <td>{'also_bought': ['0321845536', '0078787572'], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0133642984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algebra 2 California Teacher Center</td>\n",
       "      <td>731.93</td>\n",
       "      <td>{'Toys &amp; Games': 1150291}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51VK%2BL...</td>\n",
       "      <td>Prentice Hall</td>\n",
       "      <td>[[Toys &amp; Games, Learning &amp; Education, Mathemat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:15.360222Z",
     "start_time": "2025-12-09T04:20:11.364358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 只取必要字段\n",
    "df_meta = df[['asin', 'title', 'description', 'categories']].copy()\n",
    "\n",
    "# ============================================================\n",
    "# 1. 标准化文本（过滤空白、无意义内容）\n",
    "# ============================================================\n",
    "def norm_text(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, float) and pd.isna(x):\n",
    "        return None\n",
    "\n",
    "    x = str(x).strip()\n",
    "\n",
    "    # 无意义文本过滤\n",
    "    bad_tokens = {\n",
    "        \"\", \".\", \"-\", \"--\", \"...\",\n",
    "        \"N/A\", \"n/a\", \"N.a.\", \"None\", \"none\",\n",
    "        \"Unknown\", \"unknown\",\n",
    "        \"See description\", \"see description\",\n",
    "        \"No description\"\n",
    "    }\n",
    "    if x in bad_tokens:\n",
    "        return None\n",
    "\n",
    "    # 全符号（无语义）\n",
    "    if all(not c.isalnum() for c in x):\n",
    "        return None\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. 清洗 title\n",
    "# ============================================================\n",
    "df_meta['title'] = df_meta['title'].apply(norm_text)\n",
    "df_meta['title_len'] = df_meta['title'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "\n",
    "# 标题太短（<3字）视为噪声\n",
    "df_meta.loc[df_meta['title_len'] < 3, 'title'] = None\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. 清洗 description\n",
    "# ============================================================\n",
    "def clean_description(desc):\n",
    "    if isinstance(desc, str):\n",
    "        return norm_text(desc)\n",
    "\n",
    "    if isinstance(desc, list):\n",
    "        toks = [norm_text(str(t)) for t in desc if norm_text(str(t))]\n",
    "        return \" \".join(toks) if len(toks) > 0 else None\n",
    "\n",
    "    if isinstance(desc, dict):\n",
    "        flat = \" \".join([f\"{k}:{v}\" for k, v in desc.items()])\n",
    "        return norm_text(flat)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "df_meta['description'] = df_meta['description'].apply(clean_description)\n",
    "df_meta['desc_len'] = df_meta['description'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "\n",
    "# 过滤极短文本（<5）\n",
    "df_meta.loc[df_meta['desc_len'] < 5, 'description'] = None\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. 清洗 category（必须存在）\n",
    "# ============================================================\n",
    "def clean_category(cats):\n",
    "    if isinstance(cats, list) and len(cats) > 0:\n",
    "        last_path = cats[-1]\n",
    "        if isinstance(last_path, list):\n",
    "            cleaned = [norm_text(t) for t in last_path if norm_text(t)]\n",
    "            if len(cleaned) > 0:\n",
    "                return cleaned[-1]\n",
    "    return None\n",
    "\n",
    "\n",
    "df_meta['category'] = df_meta['categories'].apply(clean_category)\n",
    "\n",
    "# category 是硬约束\n",
    "df_meta = df_meta.dropna(subset=['category'])\n",
    "\n",
    "# ============================================================\n",
    "# 5. title 和 description 至少一个存在\n",
    "# ============================================================\n",
    "df_meta = df_meta[(df_meta['title'].notna()) | (df_meta['description'].notna())]\n",
    "\n",
    "# 最终结构化 df_meta（保留 asin/title/description/category）\n",
    "df_meta = df_meta[['asin', 'title', 'description', 'category']].reset_index(drop=True)\n",
    "\n",
    "print(\"Clean df_meta rows:\", len(df_meta))\n",
    "df_meta.head()"
   ],
   "id": "b8dfc81a4023c54c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean df_meta rows: 335629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         asin                                           title  \\\n",
       "0  0000191639  Dr. Suess 19163 Dr. Seuss Puzzle 3 Pack Bundle   \n",
       "1  0005069491                        Nursery Rhymes Felt Book   \n",
       "2  0076561046              Fraction Decimal Percent Card Deck   \n",
       "3  0131358936                                            None   \n",
       "4  0133642984             Algebra 2 California Teacher Center   \n",
       "\n",
       "                                         description                category  \n",
       "0  Three Dr. Suess' Puzzles: Green Eggs and Ham, ...          Jigsaw Puzzles  \n",
       "1                                               None            Toys & Games  \n",
       "2  Learn Fractions Decimals Percents using flash ...             Flash Cards  \n",
       "3  New, Sealed. Fast Shipping with tracking, buy ...  Mathematics & Counting  \n",
       "4                                               None  Mathematics & Counting  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000191639</td>\n",
       "      <td>Dr. Suess 19163 Dr. Seuss Puzzle 3 Pack Bundle</td>\n",
       "      <td>Three Dr. Suess' Puzzles: Green Eggs and Ham, ...</td>\n",
       "      <td>Jigsaw Puzzles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005069491</td>\n",
       "      <td>Nursery Rhymes Felt Book</td>\n",
       "      <td>None</td>\n",
       "      <td>Toys &amp; Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0076561046</td>\n",
       "      <td>Fraction Decimal Percent Card Deck</td>\n",
       "      <td>Learn Fractions Decimals Percents using flash ...</td>\n",
       "      <td>Flash Cards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0131358936</td>\n",
       "      <td>None</td>\n",
       "      <td>New, Sealed. Fast Shipping with tracking, buy ...</td>\n",
       "      <td>Mathematics &amp; Counting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0133642984</td>\n",
       "      <td>Algebra 2 California Teacher Center</td>\n",
       "      <td>None</td>\n",
       "      <td>Mathematics &amp; Counting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. 接下来处理review_{data}_5.json.gz\n",
    "需要考虑的是，review_{data}_5.json.gz中可能包含已经不在item table中的item，所以要进行清洗"
   ],
   "id": "1889fc8271821f05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:24.977110Z",
     "start_time": "2025-12-09T04:20:15.918522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 接下来处理review_{data}_5\n",
    "#   \"reviewerID\": \"A2SUAM1J3GNN3B\",\n",
    "#   \"asin\": \"0000013714\",\n",
    "#   \"reviewerName\": \"J. McDonald\",\n",
    "#   \"helpful\": [2, 3],\n",
    "#   \"reviewText\": \"I bought this for my husband who plays the piano.  He is having a wonderful time playing these old hymns.  The music  is at times hard to read because we think the book was published for singing from more than playing from.  Great purchase though!\",\n",
    "#   \"overall\": 5.0,\n",
    "#   \"summary\": \"Heavenly Highway Hymns\",\n",
    "#   \"unixReviewTime\": 1252800000,\n",
    "#   \"reviewTime\": \"09 13, 2009\"\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def parse_review(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def get_review_DF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse_review(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "review_file_name = f\"{args.raw_data_dir}/{args.dataset}/reviews_{args.dataset}_5.json.gz\"\n",
    "\n",
    "data_review = get_review_DF(review_file_name)\n",
    "\n",
    "print(\"Review raw data length:\", len(data_review))"
   ],
   "id": "c3beb40fb7c98fb9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review raw data length: 167597\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:25.303687Z",
     "start_time": "2025-12-09T04:20:25.291824Z"
    }
   },
   "cell_type": "code",
   "source": "data_review.head()",
   "id": "a82d4043c7d2d677",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       reviewerID        asin    reviewerName helpful  \\\n",
       "0  A1VXOAVRGKGEAK  0439893577           Angie  [0, 0]   \n",
       "1   A8R62G708TSCM  0439893577         Candace  [1, 1]   \n",
       "2  A21KH420DK0ICA  0439893577  capemaychristy  [1, 1]   \n",
       "3   AR29QK6HPFYZ4  0439893577            dcrm  [0, 0]   \n",
       "4   ACCH8EOML6FN5  0439893577            DoyZ  [1, 1]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  I like the item pricing. My granddaughter want...      5.0   \n",
       "1  Love the magnet easel... great for moving to d...      4.0   \n",
       "2  Both sides are magnetic.  A real plus when you...      5.0   \n",
       "3  Bought one a few years ago for my daughter and...      5.0   \n",
       "4  I have a stainless steel refrigerator therefor...      4.0   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                     Magnetic board      1390953600   \n",
       "1  it works pretty good for moving to different a...      1395964800   \n",
       "2                                         love this!      1359331200   \n",
       "3                                  Daughters love it      1391817600   \n",
       "4  Great to have so he can play with his alphabet...      1399248000   \n",
       "\n",
       "    reviewTime  \n",
       "0  01 29, 2014  \n",
       "1  03 28, 2014  \n",
       "2  01 28, 2013  \n",
       "3   02 8, 2014  \n",
       "4   05 5, 2014  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1VXOAVRGKGEAK</td>\n",
       "      <td>0439893577</td>\n",
       "      <td>Angie</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I like the item pricing. My granddaughter want...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Magnetic board</td>\n",
       "      <td>1390953600</td>\n",
       "      <td>01 29, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A8R62G708TSCM</td>\n",
       "      <td>0439893577</td>\n",
       "      <td>Candace</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Love the magnet easel... great for moving to d...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>it works pretty good for moving to different a...</td>\n",
       "      <td>1395964800</td>\n",
       "      <td>03 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A21KH420DK0ICA</td>\n",
       "      <td>0439893577</td>\n",
       "      <td>capemaychristy</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Both sides are magnetic.  A real plus when you...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>love this!</td>\n",
       "      <td>1359331200</td>\n",
       "      <td>01 28, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR29QK6HPFYZ4</td>\n",
       "      <td>0439893577</td>\n",
       "      <td>dcrm</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Bought one a few years ago for my daughter and...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Daughters love it</td>\n",
       "      <td>1391817600</td>\n",
       "      <td>02 8, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACCH8EOML6FN5</td>\n",
       "      <td>0439893577</td>\n",
       "      <td>DoyZ</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>I have a stainless steel refrigerator therefor...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great to have so he can play with his alphabet...</td>\n",
       "      <td>1399248000</td>\n",
       "      <td>05 5, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:25.856549Z",
     "start_time": "2025-12-09T04:20:25.443423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "data_review_copy = data_review[['reviewerID', 'asin', 'unixReviewTime']].copy()\n",
    "\n",
    "data_review_copy['unixReviewTime'] = data_review_copy['unixReviewTime'].astype(int)\n",
    "\n",
    "# 保留 metadata 中存在的 asin\n",
    "valid_asin_id = set(df_meta['asin'].values)\n",
    "data_review_copy = data_review_copy[data_review_copy['asin'].isin(valid_asin_id)]\n",
    "\n",
    "# 时间戳必须大于 0\n",
    "data_review_copy = data_review_copy[data_review_copy['unixReviewTime'] > 0]\n",
    "\n",
    "data_review_copy = data_review_copy.reset_index(drop=True)\n",
    "\n",
    "print(\"Review data after merging with metadata:\", len(data_review_copy))\n"
   ],
   "id": "92f3745bdcfb3f90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review data after merging with metadata: 167101\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:26.484425Z",
     "start_time": "2025-12-09T04:20:26.036576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 反复清洗review_{data}_5.json.gz；直至 >= 5稳定后再重映射\n",
    "def iterative_filter(df, min_user=5, min_item=5):\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "\n",
    "        # ---- filter items ----\n",
    "        item_counts = df['asin'].value_counts()\n",
    "        valid_items = item_counts[item_counts >= min_item].index\n",
    "        new_df = df[df['asin'].isin(valid_items)]\n",
    "        if len(new_df) != len(df):\n",
    "            changed = True\n",
    "        df = new_df\n",
    "\n",
    "        # ---- filter users ----\n",
    "        user_counts = df['reviewerID'].value_counts()\n",
    "        valid_users = user_counts[user_counts >= min_user].index\n",
    "        new_df = df[df['reviewerID'].isin(valid_users)]\n",
    "        if len(new_df) != len(df):\n",
    "            changed = True\n",
    "        df = new_df\n",
    "\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "data_review_clean = iterative_filter(data_review_copy)\n",
    "print(\"After iterative filtering:\", len(data_review_clean))"
   ],
   "id": "324fc053a6b223b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After iterative filtering: 166043\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:26.523519Z",
     "start_time": "2025-12-09T04:20:26.518470Z"
    }
   },
   "cell_type": "code",
   "source": "len(df_meta)",
   "id": "fd5bd3c73cb0d722",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335629"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:26.722549Z",
     "start_time": "2025-12-09T04:20:26.576887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 清洗完review_{data}_5.json.gz后需要对item table进行筛选\n",
    "valid_asins = set(data_review_clean['asin'].unique())\n",
    "df_meta_clean = df_meta[df_meta['asin'].isin(valid_asins)]\n",
    "\n",
    "print('After cleaning get df_meta_clean length:', len(df_meta_clean))\n"
   ],
   "id": "8246fcd7ade85e63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning get df_meta_clean length: 11811\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. user/item重映射，并按userID-unixReviewTime进行排序",
   "id": "74dda79ec774ac01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:27.147234Z",
     "start_time": "2025-12-09T04:20:26.753170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "dataset_dir = f\"{args.processed_data_dir}/{args.dataset}\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "df_ = data_review_clean\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: 获取唯一用户和物品\n",
    "# -----------------------------\n",
    "unique_users = sorted(df_['reviewerID'].unique())\n",
    "unique_items = sorted(df_['asin'].unique())\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: 构建映射字典（为了配合本项目中backbone_SASRec的代码逻辑“padding_idx=item_num”，所以itemID必须从 0 开始计数）\n",
    "# -----------------------------\n",
    "user2id = {u: i for i, u in enumerate(unique_users)}\n",
    "id2user = {i: u for i, u in enumerate(unique_users)}\n",
    "\n",
    "item2id = {a: i for i, a in enumerate(unique_items)}\n",
    "id2item = {i: a for i, a in enumerate(unique_items)}\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: 应用映射到交互表\n",
    "# -----------------------------\n",
    "df_['user_id'] = df_['reviewerID'].map(user2id)\n",
    "df_['item_id'] = df_['asin'].map(item2id)\n",
    "\n",
    "df_ = df_[['user_id', 'item_id', 'unixReviewTime']]\n",
    "df_ = df_.sort_values(['user_id', 'unixReviewTime']).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: 保存映射文件\n",
    "# -----------------------------\n",
    "with open(f\"{dataset_dir}/user2id.json\", \"w\") as f:\n",
    "    json.dump(user2id, f)\n",
    "\n",
    "with open(f\"{dataset_dir}/id2user.json\", \"w\") as f:\n",
    "    json.dump(id2user, f)\n",
    "\n",
    "with open(f\"{dataset_dir}/item2id.json\", \"w\") as f:\n",
    "    json.dump(item2id, f)\n",
    "\n",
    "with open(f\"{dataset_dir}/id2item.json\", \"w\") as f:\n",
    "    json.dump(id2item, f)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 5: 保存重映射后的交互表\n",
    "# -----------------------------\n",
    "df_.to_csv(f\"{dataset_dir}/interactions.csv\", index=False)\n",
    "\n",
    "print(\"Remapping done!\")\n",
    "print(\"#Users =\", len(unique_users))\n",
    "print(\"#Items =\", len(unique_items))\n",
    "print(\"Mapped interactions saved to:\", f\"{dataset_dir}/interactions.csv\")\n"
   ],
   "id": "13e1e0d32858ee82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remapping done!\n",
      "#Users = 19220\n",
      "#Items = 11811\n",
      "Mapped interactions saved to: ../dataset/Toys_and_Games/interactions.csv\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:27.425958Z",
     "start_time": "2025-12-09T04:20:27.177907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# 重新基于 valid_asins 进一步过滤 meta（不会覆盖清洗结果）\n",
    "# ============================================================\n",
    "\n",
    "df_meta_clean = df_meta[df_meta['asin'].isin(valid_asins)].copy()\n",
    "\n",
    "print(\"meta rows after valid_asins filter:\", len(df_meta_clean))\n",
    "\n",
    "# 添加 item_id\n",
    "df_meta_clean['item_id'] = df_meta_clean['asin'].map(item2id)\n",
    "\n",
    "# 丢弃 mapping 失败的\n",
    "df_meta_clean = df_meta_clean.dropna(subset=['item_id'])\n",
    "df_meta_clean['item_id'] = df_meta_clean['item_id'].astype(int)\n",
    "\n",
    "# 最终列\n",
    "df_meta_clean = df_meta_clean[['item_id', 'title', 'description', 'category']]\n",
    "df_meta_clean = df_meta_clean.reset_index(drop=True)\n",
    "\n",
    "# 保存 item_text.csv\n",
    "df_meta_clean.to_csv(f\"{dataset_dir}/item_text.csv\", index=False)\n",
    "\n",
    "print(\"Saved structured item_text.csv. Final rows:\", len(df_meta_clean))\n",
    "df_meta_clean.head()\n"
   ],
   "id": "3c26aa9723504090",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta rows after valid_asins filter: 11811\n",
      "Saved structured item_text.csv. Final rows: 11811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   item_id                                              title  \\\n",
       "0        0  Little Red Tool Box: Magnetic Tabletop Learnin...   \n",
       "1        1  Dover Publications-Decorative Tile Designs Col...   \n",
       "2        2  The Book of Impossible Objects: 25 Eye-Popping...   \n",
       "3        3  Original Sticker Book Starter Kit with 3 Puffy...   \n",
       "4        4                                  Llama Llama Plush   \n",
       "\n",
       "                                         description                  category  \n",
       "0  The Magnetic Tabletop Learning Easel is one of...  Magnet & Felt Playboards  \n",
       "1                                               None     Drawing & Sketch Pads  \n",
       "2                                               None  Magic Kits & Accessories  \n",
       "3  Our Original Sticker Books follow friends and ...             Play Vehicles  \n",
       "4  Cuddle up with little llama llama, star ofLlam...         Animals & Figures  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Little Red Tool Box: Magnetic Tabletop Learnin...</td>\n",
       "      <td>The Magnetic Tabletop Learning Easel is one of...</td>\n",
       "      <td>Magnet &amp; Felt Playboards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dover Publications-Decorative Tile Designs Col...</td>\n",
       "      <td>None</td>\n",
       "      <td>Drawing &amp; Sketch Pads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Book of Impossible Objects: 25 Eye-Popping...</td>\n",
       "      <td>None</td>\n",
       "      <td>Magic Kits &amp; Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Original Sticker Book Starter Kit with 3 Puffy...</td>\n",
       "      <td>Our Original Sticker Books follow friends and ...</td>\n",
       "      <td>Play Vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Llama Llama Plush</td>\n",
       "      <td>Cuddle up with little llama llama, star ofLlam...</td>\n",
       "      <td>Animals &amp; Figures</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:27.593554Z",
     "start_time": "2025-12-09T04:20:27.543220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_dir = f\"{args.processed_data_dir}/{args.dataset}\"\n",
    "inter_path = f\"{dataset_dir}/interactions.csv\"\n",
    "\n",
    "inter_df = pd.read_csv(inter_path)\n",
    "inter_df.head()"
   ],
   "id": "a358e7b23431921a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user_id  item_id  unixReviewTime\n",
       "0        0     3814      1356220800\n",
       "1        0     9153      1356220800\n",
       "2        0      566      1360108800\n",
       "3        0     4490      1360108800\n",
       "4        0     5921      1360108800"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3814</td>\n",
       "      <td>1356220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9153</td>\n",
       "      <td>1356220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>566</td>\n",
       "      <td>1360108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4490</td>\n",
       "      <td>1360108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5921</td>\n",
       "      <td>1360108800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. 切分数据集并生成数据集信息",
   "id": "9cdb320bccedb94d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:28.453272Z",
     "start_time": "2025-12-09T04:20:27.925328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, json\n",
    "\n",
    "dataset_dir = f\"{args.processed_data_dir}/{args.dataset}\"\n",
    "inter_path = f\"{dataset_dir}/interactions.csv\"\n",
    "\n",
    "inter_df = pd.read_csv(inter_path)\n",
    "inter_df = inter_df.sort_values(['user_id', 'unixReviewTime'])\n",
    "\n",
    "# -----------------------------\n",
    "# Build user → sequence mapping\n",
    "# -----------------------------\n",
    "user2seq = {}\n",
    "for r in inter_df.itertuples():\n",
    "    user2seq.setdefault(r.user_id, []).append(r.item_id)\n",
    "\n",
    "train_rows, valid_rows, test_rows = [], [], []\n",
    "\n",
    "for user, seq in user2seq.items():\n",
    "    L = len(seq)\n",
    "    if L < 4:\n",
    "        continue\n",
    "\n",
    "    # ---- train ----\n",
    "    train_seq = seq[:-3]\n",
    "    train_next = seq[-3]\n",
    "    train_rows.append([user, train_seq, train_next, len(train_seq)])\n",
    "\n",
    "    # ---- valid ----\n",
    "    valid_seq = seq[:-2]\n",
    "    valid_next = seq[-2]\n",
    "    valid_rows.append([user, valid_seq, valid_next, len(valid_seq)])\n",
    "\n",
    "    # ---- test ----\n",
    "    test_seq = seq[:-1]\n",
    "    test_next = seq[-1]\n",
    "    test_rows.append([user, test_seq, test_next, len(test_seq)])\n",
    "\n",
    "train_df = pd.DataFrame(train_rows, columns=['user_id', 'seq', 'next', 'len_seq'])\n",
    "valid_df = pd.DataFrame(valid_rows, columns=['user_id', 'seq', 'next', 'len_seq'])\n",
    "test_df  = pd.DataFrame(test_rows,  columns=['user_id', 'seq', 'next', 'len_seq'])\n",
    "\n",
    "# -----------------------------\n",
    "# Save df files\n",
    "# -----------------------------\n",
    "train_df.to_pickle(f\"{dataset_dir}/train_data.df\")\n",
    "valid_df.to_pickle(f\"{dataset_dir}/val_data.df\")\n",
    "test_df.to_pickle(f\"{dataset_dir}/test_data.df\")\n",
    "\n",
    "print(\"train:\", len(train_df))\n",
    "print(\"valid:\", len(valid_df))\n",
    "print(\"test :\", len(test_df))\n",
    "\n",
    "# -----------------------------\n",
    "# Build dataset_info.csv\n",
    "# -----------------------------\n",
    "num_users = inter_df.user_id.nunique()\n",
    "num_items = inter_df.item_id.nunique()\n",
    "total_interactions = len(inter_df)\n",
    "\n",
    "seq_lens = [len(v) for v in user2seq.values()]\n",
    "avg_seq_len = np.mean(seq_lens)\n",
    "median_seq_len = np.median(seq_lens)\n",
    "\n",
    "# Sparsity：1 - (nnz / (num_users * num_items))\n",
    "sparsity = 1 - (total_interactions / (num_users * num_items))\n",
    "\n",
    "dataset_info = {\n",
    "    \"num_users\": num_users,\n",
    "    \"num_items\": num_items,\n",
    "    \"total_interactions\": total_interactions,\n",
    "    \"avg_seq_len\": round(avg_seq_len, 3),\n",
    "    \"median_seq_len\": median_seq_len,\n",
    "    \"min_seq_len\": min(seq_lens),\n",
    "    \"max_seq_len\": max(seq_lens),\n",
    "    \"sparsity\": round(sparsity, 6),\n",
    "    \"train_samples\": len(train_df),\n",
    "    \"valid_samples\": len(valid_df),\n",
    "    \"test_samples\": len(test_df),\n",
    "}\n",
    "\n",
    "pd.DataFrame([dataset_info]).to_csv(f\"{dataset_dir}/{args.dataset}_info.csv\", index=False)\n",
    "\n",
    "print(\"Dataset info saved:\", f\"{dataset_dir}/{args.dataset}_info.csv\")\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# Save data_statis.df (AlphaFuse required)\n",
    "# ---------------------------------\n",
    "stat = {\n",
    "    \"item_num\": num_items,\n",
    "    \"user_num\": num_users\n",
    "}\n",
    "pd.DataFrame([stat]).to_pickle(f\"{dataset_dir}/data_statis.df\")\n",
    "\n",
    "print(\"Saved:\", f\"{dataset_dir}/data_statis.df\")\n",
    "\n",
    "end_time = datetime.now().strftime(\"%Y//%m//%d-%H//%M//%S\")\n",
    "print(f\"Finish processing at {end_time}\")\n"
   ],
   "id": "872029d602985aac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 19220\n",
      "valid: 19220\n",
      "test : 19220\n",
      "Dataset info saved: ../dataset/Toys_and_Games/Toys_and_Games_info.csv\n",
      "Saved: ../dataset/Toys_and_Games/data_statis.df\n",
      "Finish processing at 2025//12//09-12//20//28\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T04:20:28.613236Z",
     "start_time": "2025-12-09T04:20:28.609090Z"
    }
   },
   "cell_type": "code",
   "source": "print(dataset_info)",
   "id": "18b032155f96998f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_users': 19220, 'num_items': 11811, 'total_interactions': 166043, 'avg_seq_len': 8.639, 'median_seq_len': 6.0, 'min_seq_len': 5, 'max_seq_len': 548, 'sparsity': 0.999269, 'train_samples': 19220, 'valid_samples': 19220, 'test_samples': 19220}\n"
     ]
    }
   ],
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
